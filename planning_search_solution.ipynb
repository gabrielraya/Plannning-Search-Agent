{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a Planning Search Agent\n",
    "\n",
    "## Synopsis\n",
    "\n",
    "<div style=\"text-align: justify\"> \n",
    "In this notebook we are going to solve <strong>deterministic logistics planning problemes</strong> for an <strong>Air Carto Transport</strong> system using a <strong>planning search agent</strong>. With progression search algorithm optimal plans for each problem will be computed. And Domain-independet heuristics will be implemented.\n",
    "\n",
    "First take a look to [Summary](summary.ipynb) to see the big picture before going deep into Planning.\n",
    "\n",
    "Firt of all, let's talk about <b> Classical Planning </b>.which covers Chapters 10 (Classical Planning) *[Artificial Intelligence: A Modern Approach](http://aima.cs.berkeley.edu)*.  \n",
    "</div>\n",
    "\n",
    "![Progression air cargo search](images/Progression.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Agents\n",
    "The intelligence of humans is achieved not by purely mechanisms but by processes of <strong>reasoning</strong> that operate on internal <strong>representations</strong> of knowledge. In AI, this approach to intelligence is embodied in <strong>knowledge-based agents</strong>.\n",
    "\n",
    "As the process of <strong>reasoning</strong> embodies representation of knowledge, to represent this a syntax must be used. \n",
    "Compared with the classical propositional logic, where a fact can be evaluated as true or false,\n",
    "\n",
    "There is three different representations\n",
    "* The atomic representation: used by problem-solving agents are very limiting. \n",
    "* Factored representation: an individual state of the world is factored into several variables. Chapter 6 presented this idea of representing states as assigments of values to variables; this is a step in the right direction, enabling some parts of the agent to work in a domain-indepent way and allowing for more efficient algorithms. \n",
    "* Structured representation: an individual state is not just a set of values for variables, but it can include relationships between objects, a branching structure, and complex representations.\n",
    "\n",
    "In this chapter we'll use the <strong>factored representation</strong> to support knowledge-based agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Planning \n",
    "<div style=\"text-align: justify\"> \n",
    "The task of coming up with a sequence of actions that will achieve a goal is called <b>planning</b>\n",
    "In this project we consider only environments that are fully observable, deterministic, finite, static(change happens only when the agent acts), and discrete (in time, action, objects, and effects). These are called <b>classical planning</b> environments. In contrast, nonclassical planning is for partially observable or stochastic environments and involves a different set of algorithms and agent designs. \n",
    "</div>\n",
    "# Propositional Logic\n",
    "<div style=\"text-align: justify\"> \n",
    "1. PL is not expressive enough to describe all the world around us. It can't express ifnormation about different object and the relation between objects.<br>\n",
    "2. PL is not compact. It can't express a fact for a set of objects without enumerating all of them which is sometimes impossible (like the wumpus world or a 10x10 roomba)\n",
    "</div>\n",
    "\n",
    "# First Order Logic\n",
    "<div style=\"text-align: justify\"> \n",
    "Alternative to PL: Another more powerfull, <strong>First Order Logic(FOL)</strong> \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Planning Problem\n",
    "<br>\n",
    "<div style=\"text-align: justify\"> \n",
    "AI is the study of rational action, which means that <b>planning</b> --devising a plan of action to achieve one's goal-- is critical part of AI.In this project we consider only environments that are fully observable, deterministic, finite, static(change happens only when the agent acts), and discrete (in time, action, objects, and effects). These are called <b>classical planning</b> environments. In contrast, nonclassical planning is for partially observable or stochastic environments and involves a different set of algorithms and agent designs. \n",
    "</div><br>\n",
    "\n",
    "<div style=\"text-align: justify\"> \n",
    "We came up with this idea of <em>planning</em> because planning allows us to scale up to problems taht could not be handled by techniques such as search and constraint satisfaction. The <strong>problem-solving agent</strong> can find sequences of actions that result in a goal state. But it deals with atomic representations of states and thus needs good domain-specific heuristics to perform well. In contrast, the <strong>hybrid propositional logical agent</strong> presented in the wumpus world, can find plans without domain-specific heuristics because it uses domain-independent heuristics based on the logical structure of the problem. But it relies on ground (variable-free) propositional inference, which means that it may be swamped when there are many actions and states. For example, In the wumpus world, the simple action of movin a step forward had to be repeated for all four agent orientations, <em>T</em> time steps, and <i>n</i><sup>2</sup> current locations.</div><br>\n",
    "<div style=\"text-align: justify\"> \n",
    "In response to this, planning researchers have settled on a <strong>factored representation</strong>--one in which a state of the world is represented by a collection of variables. We use a language called <strong>PDDL</strong>, the Planning Domain Definition Langauge, that allows us to express all <i>4Tn</i><sup>2</sup> actions with one action schema.\n",
    "</div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning in a few words\n",
    "\n",
    "Planning uses a new notation(PDDL), this new notation allows us instead of writing plans as a linear sequence of actions, we can write them as a tree structure where a each state we can perceive if the result of \"planning vs execution\" to validate if the result is what we expected to be. \n",
    "\n",
    "This language is also known as Classical Planning which is a representation language for dealing with states and actions and plans. And it's also an approach for dealing with the problem of complexity by factoring the world into variables. \n",
    "\n",
    "It has a \"choice point\" that allos the idea of inifinitive actions as the tree can loop infinity depending on the choice (very similar feedback control).\n",
    "PDDL allows to express all actions with one action schema. PDDL describes the four things we need to define a search problem:\n",
    "- the initial state\n",
    "- the actiosn that are available in a state\n",
    "- the result of applying an action\n",
    "- the goal test\n",
    "\n",
    "### Finding a succesful plan\n",
    "\n",
    "The process of finding can be done through a search just as we did in problem solving only the tree is a bit more complicated. \n",
    "Basically, what we do is we search through the tree, we try some actions(same as we did in problem-solving) until we find a portion of the tree (choice poin). We find that portion, which is the succesful plan according to the criteria of reaching a goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning in a few words\n",
    "\n",
    "This language is also known as Classical Planning which is a representation language for dealing with states and actions and plans. And it's also an approach for dealing with the problem of complexity by factoring the world into variables. \n",
    " \n",
    "#### Classical Planning\n",
    "\n",
    "**How states look like?**\n",
    "- state space : all the possible assigments to k-boolean variables, that means <i>2</i><sup>k</sup>  states but now it is only represented by this k variables. \n",
    "- World state : complete assigment of true or false through each of the k variables\n",
    "- Belief state : depends on the type of environment. Has to be a complete assigment. \n",
    "- the goal test\n",
    "\n",
    "**How actions look like?**\n",
    "- Action Schema: represents many possible actions that are similar to each other.\n",
    "\n",
    "**How an action schema is built?**\n",
    "- Action(operator, arguments): example Action(Fly(p,x,y))\n",
    "- PRECOND: It is what needs to be true in order to execute this action(Fly). Ex: Plane(p)^Airport(x)^Airport(y)^At(p,x)\n",
    "- EFFECTS: notAt(p,x) ^ At(p,y)\n",
    "\n",
    "The advange of this is that we can apply this schema to specific ground states, specific world states, \n",
    "\n",
    "**How "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State representation\n",
    "\n",
    "Like any other logic we need a syntaxis and the semantic part to develop a formal language to work with. See [**Intro to Logic**](logic.ipynb) to understand better the language we are going to use to treat any other Planning problem and to establish a PDDL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Expr class to describe action in PDDL (Planning Domain Defined Language)\n",
    "from aimacode.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each <strong>state</strong> is represented as a conjunction of fluents that are ground, functionless atoms. For example lets implement the Fly action schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%psource fly_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Action' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-aee47fbc4a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0meffect_rem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At({}, {})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m fly = Action(expr(\"Fly({}, {}, {})\".format(p, fr, to)),\n\u001b[0m\u001b[1;32m     10\u001b[0m              \u001b[1;33m[\u001b[0m\u001b[0mprecond_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecond_neg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m              [effect_add, effect_rem])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Action' is not defined"
     ]
    }
   ],
   "source": [
    "p  = Symbol('plane')\n",
    "fr = Symbol('from_airport')\n",
    "to = Symbol('to_airport')\n",
    "precond_pos = [expr(\"At({}, {})\".format(p, fr)),]\n",
    "precond_neg = []\n",
    "effect_add = [expr(\"At({}, {})\".format(p, to))]\n",
    "effect_rem = [expr(\"At({}, {})\".format(p, fr))]\n",
    "\n",
    "fly = Action(expr(\"Fly({}, {}, {})\".format(p, fr, to)),\n",
    "             [precond_pos, precond_neg],\n",
    "             [effect_add, effect_rem])\n",
    "flys.append(fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Poor ^ Unknown)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Poor ^ Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precond_pos = [expr(\"Human(person)\"), expr(\"Hungry(Person)\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Human(person), Hungry(Person)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precond_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Planning with State-space Search\n",
    "\n",
    "\n",
    "<div style=\"text-align: justify\"> \n",
    "The task of coming up with a sequence of actions that will achieve a goal is called <b>planning</b>\n",
    "In this project we consider only environments that are fully observable, deterministic, finite, static(change happens only when the agent acts), and discrete (in time, action, objects, and effects). These are called <b>classical planning</b> environments. In contrast, nonclassical planning is for partially observable or stochastic environments and involves a different set of algorithms and agent designs. \n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"text-align: justify\"> \n",
    "</div>\n",
    "<div style=\"text-align: justify\"> \n",
    "</div>\n",
    "<div style=\"text-align: justify\"> \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
